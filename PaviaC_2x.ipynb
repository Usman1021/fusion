{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8d36ef-2dff-4215-b798-08f878057a3d",
   "metadata": {},
   "source": [
    "## A Fusion-Guided Inception Network for Hyperspectral Image Super-Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a67e0d5a-f4e5-472a-a2f2-e0c16e43f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 01:56:54.479975: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 01:56:54.499513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741564614.521248  800109 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741564614.528155  800109 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 01:56:54.553286: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from scipy.io import loadmat \n",
    "from spectral import open_image\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, DepthwiseConv2D, BatchNormalization, Activation, Add,\n",
    "    UpSampling2D, Conv2DTranspose, Input, Concatenate, GlobalAveragePooling2D, Multiply, Dense, Lambda\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c99148",
   "metadata": {},
   "source": [
    "## preprocess Pavia Center University dataset for band grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c42d49-16d8-4cca-8335-0b3f16c54bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741564637.809338  800109 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_hr shape: (175, 128, 128, 128)\n",
      "X_validation_hr shape: (20, 128, 128, 128)\n",
      "X_test_hr shape: (60, 128, 128, 128)\n",
      "X_train_lr shape: (175, 32, 32, 128)\n",
      "X_validation_lr shape: (20, 32, 32, 128)\n",
      "X_test_lr shape: (60, 32, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "###### Set random seeds for reproducibility\n",
    "\n",
    "# Set all seeds for reproducibility\n",
    "seed_value = 42\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# Ensure TensorFlow uses deterministic operations\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load the Pavia dataset\n",
    "try:\n",
    "    data = loadmat(\"Pavia.mat\")  # Ensure that the file path is correct\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Error loading .mat file: {e}\")\n",
    "\n",
    "# Access the hyperspectral image using the correct key 'pavia'\n",
    "print(\"Keys in loaded .mat file:\", data.keys())\n",
    "if 'pavia' in data:\n",
    "    hyperspectral_image = data['pavia']\n",
    "else:\n",
    "    raise KeyError(\"'pavia' not found in the .mat file.\")\n",
    "\n",
    "# Check the shape of the hyperspectral image\n",
    "print(\"Hyperspectral image shape:\", hyperspectral_image.shape)\n",
    "\n",
    "# Convert to float32 for TensorFlow operations\n",
    "hyperspectral_image = hyperspectral_image.astype(np.float32)\n",
    "\n",
    "# Load the hyperspectral data using the spectral library\n",
    "data = hyperspectral_image  # Use the loaded hyperspectral image directly\n",
    "\n",
    "# Parameters\n",
    "patch_size = (144, 144)  # Size of patches to extract\n",
    "test_size = 0.2  # Proportion of data for testing\n",
    "validation_size = 0.1  # Proportion of data for validation\n",
    "downscale_factor = 8  # Factor to downscale patches\n",
    "nodata_value = -1  # Value that indicates \"no data\"\n",
    "group_size = 8 # Group size for spectral bands\n",
    "overlap_size = 2  # Overlap size for grouped bands\n",
    "\n",
    "# Function to group bands into overlapping subgroups\n",
    "def group_bands_with_overlap(data, group_size=6, overlap_size=2):\n",
    "    height, width, bands = data.shape\n",
    "    step_size = group_size - overlap_size  # Calculate step size based on overlap\n",
    "    grouped_data = []\n",
    "\n",
    "    # Create overlapping groups of bands\n",
    "    for g in range(0, bands - group_size + 1, step_size):\n",
    "        group = data[:, :, g:g + group_size]\n",
    "        grouped_data.append(group)\n",
    "    \n",
    "    return np.array(grouped_data)\n",
    "\n",
    "# Extract and downscale patches from hyperspectral data\n",
    "def extract_and_downscale_patches(data, patch_size, downscale_factor, nodata_value=0):\n",
    "    patches_hr = []\n",
    "    patches_lr = []\n",
    "    height, width, bands = data.shape\n",
    "\n",
    "    for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            patch_hr = data[i:i + patch_size[0], j:j + patch_size[1], :]\n",
    "\n",
    "            # Check for nodata_value and skip patch extraction if present\n",
    "            if np.any(patch_hr == nodata_value):\n",
    "                continue\n",
    "            \n",
    "            patch_lr = tf.image.resize(patch_hr, \n",
    "                                        [patch_size[0] // downscale_factor, patch_size[1] // downscale_factor], \n",
    "                                        method='bilinear')\n",
    "            patches_hr.append(patch_hr)\n",
    "            patches_lr.append(patch_lr.numpy())  # Convert tensor to numpy\n",
    "\n",
    "    return np.array(patches_hr), np.array(patches_lr)\n",
    "\n",
    "# Group bands into overlapping subgroups\n",
    "grouped_data = group_bands_with_overlap(hyperspectral_image, group_size=group_size, overlap_size=overlap_size)\n",
    "\n",
    "# Extract and downscale patches for all groups\n",
    "all_patches_hr = []\n",
    "all_patches_lr = []\n",
    "\n",
    "for group in grouped_data:\n",
    "    patches_hr, patches_lr = extract_and_downscale_patches(group, patch_size, downscale_factor, nodata_value=nodata_value)\n",
    "    all_patches_hr.append(patches_hr)\n",
    "    all_patches_lr.append(patches_lr)\n",
    "\n",
    "# Concatenate patches from all groups\n",
    "all_patches_hr = np.concatenate(all_patches_hr, axis=0)\n",
    "all_patches_lr = np.concatenate(all_patches_lr, axis=0)\n",
    "\n",
    "# Calculate the number of patches\n",
    "num_patches = len(all_patches_hr)\n",
    "\n",
    "# Calculate sizes for training, validation, and testing sets\n",
    "train_size = int((1 - test_size - validation_size) * num_patches)\n",
    "validation_size = int(validation_size * num_patches)\n",
    "test_size = num_patches - (train_size + validation_size)  # Explicit calculation of test size\n",
    "\n",
    "# Shuffle indices for splitting the data\n",
    "indices = np.arange(num_patches)\n",
    "np.random.shuffle(indices)\n",
    "all_patches_hr = all_patches_hr[indices]\n",
    "all_patches_lr = all_patches_lr[indices]\n",
    "\n",
    "# Split into training, validation, and testing sets\n",
    "X_train_hr, X_validation_hr, X_test_hr = np.split(all_patches_hr, [train_size, train_size + validation_size])\n",
    "X_train_lr, X_validation_lr, X_test_lr = np.split(all_patches_lr, [train_size, train_size + validation_size])\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train_hr shape:\", X_train_hr.shape)\n",
    "print(\"X_validation_hr shape:\", X_validation_hr.shape)\n",
    "print(\"X_test_hr shape:\", X_test_hr.shape)\n",
    "\n",
    "print(\"X_train_lr shape:\", X_train_lr.shape)\n",
    "print(\"X_validation_lr shape:\", X_validation_lr.shape)\n",
    "print(\"X_test_lr shape:\", X_test_lr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616915db",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6850655-113a-4947-b618-e4e420ce0b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in loaded .mat file: dict_keys(['__header__', '__version__', '__globals__', 'paviaU'])\n",
      "Hyperspectral image shape: (610, 340, 103)\n",
      "X_train_hr shape: (16, 144, 144, 30)\n",
      "X_validation_hr shape: (2, 144, 144, 30)\n",
      "X_test_hr shape: (6, 144, 144, 30)\n",
      "X_train_lr shape: (16, 72, 72, 30)\n",
      "X_validation_lr shape: (2, 72, 72, 30)\n",
      "X_test_lr shape: (6, 72, 72, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741353022.971803  401555 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Inception Block\n",
    "# -----------------------------\n",
    "def inception_block(x, filters, l2_reg=1e-4):\n",
    "    branch1x1 = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    branch3x3 = Conv2D(filters, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    branch5x5 = Conv2D(filters, (5, 5), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    branch_pool = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    \n",
    "    x = Concatenate()([branch1x1, branch3x3, branch5x5, branch_pool])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# -----------------------------\n",
    "# Dilated Convolution Fusion Block\n",
    "# -----------------------------\n",
    "def dilated_convolution_fusion_block(x, filters, l2_reg=1e-4):\n",
    "    spatial_branch = Conv2D(filters, (3, 3), dilation_rate=2, padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    spectral_branch = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    \n",
    "    x = Add()([spatial_branch, spectral_branch])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "# -----------------------------\n",
    "# Spectral-Spatial Fusion Block\n",
    "# -----------------------------\n",
    "def spectral_spatial_fusion_block(x, filters, l2_reg=1e-4):\n",
    "    spatial_features = Conv2D(filters, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    spectral_features = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    \n",
    "    x = Concatenate()([spatial_features, spectral_features])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "# -----------------------------\n",
    "# Custom Loss Functions\n",
    "# -----------------------------\n",
    "def custom_loss_with_l2(y_true, y_pred, model):\n",
    "    mse_loss = K.mean(K.square(y_true - y_pred))\n",
    "    l2_loss_val = sum(K.sum(K.square(w)) for w in model.trainable_weights)\n",
    "    l2_penalty = 1e-4 * l2_loss_val\n",
    "    return mse_loss + l2_penalty\n",
    "\n",
    "def spatial_spectral_gradient_loss(y_true, y_pred):\n",
    "    grad_true_x, grad_true_y = tf.image.image_gradients(y_true)\n",
    "    grad_pred_x, grad_pred_y = tf.image.image_gradients(y_pred)\n",
    "    \n",
    "    spatial_loss = K.mean(K.square(grad_true_x - grad_pred_x) + K.square(grad_true_y - grad_pred_y))\n",
    "    \n",
    "    grad_true_spectral = tf.gradients(tf.reduce_mean(y_true, axis=[1, 2]), y_true)[0]\n",
    "    grad_pred_spectral = tf.gradients(tf.reduce_mean(y_pred, axis=[1, 2]), y_pred)[0]\n",
    "    \n",
    "    spectral_loss = K.mean(K.square(grad_true_spectral - grad_pred_spectral))\n",
    "    \n",
    "    return spatial_loss + spectral_loss\n",
    "\n",
    "def combined_loss(y_true, y_pred, model):\n",
    "    return custom_loss_with_l2(y_true, y_pred, model) + spatial_spectral_gradient_loss(y_true, y_pred)\n",
    "# -----------------------------\n",
    "# Spectral-Spatial Fusion Block\n",
    "# -----------------------------\n",
    "def spectral_spatial_fusion_block(x, filters, l2_reg=1e-4):\n",
    "    spatial_features = Conv2D(filters, (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    spectral_features = Conv2D(filters, (1, 1), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
    "    \n",
    "    x = Concatenate()([spatial_features, spectral_features])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# -----------------------------\n",
    "# Enhanced Upsampling Block for 2X Scaling\n",
    "# -----------------------------\n",
    "def upsample_block(x, filters, scale=2, use_residual=False, use_depthwise=False, use_transpose=False):\n",
    "    for _ in range(1):  # 2^1 = 2x scaling\n",
    "        if not use_transpose:\n",
    "            shortcut = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "            shortcut = Conv2D(filters, (3, 3), padding='same')(shortcut)\n",
    "            \n",
    "            x = UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "            if use_depthwise:\n",
    "                x = DepthwiseConv2D((3, 3), padding='same')(x)\n",
    "                x = BatchNormalization()(x)\n",
    "                x = Activation('relu')(x)\n",
    "                x = Conv2D(filters, (1, 1), padding='same')(x)\n",
    "            else:\n",
    "                x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "        else:\n",
    "            shortcut = Conv2DTranspose(filters, (3, 3), strides=2, padding='same')(x)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            shortcut = Activation('relu')(shortcut)\n",
    "            \n",
    "            x = Conv2DTranspose(filters, (3, 3), strides=2, padding='same')(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation('relu')(x)\n",
    "        \n",
    "        if use_residual:\n",
    "            x = Add()([x, shortcut])\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Model Definition with 2X Scaling\n",
    "# -----------------------------\n",
    "def build_residual_cnn_sr_model(input_shape, use_depthwise=False, use_transpose=False, l2_reg=1e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    x = inception_block(inputs, filters=32, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=32, l2_reg=l2_reg)\n",
    "    x = spectral_spatial_fusion_block(x, filters=32, l2_reg=l2_reg)\n",
    "    \n",
    "    x = inception_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=64, l2_reg=l2_reg)\n",
    "    x = spectral_spatial_fusion_block(x, filters=64, l2_reg=l2_reg)\n",
    "    \n",
    "    x = inception_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = dilated_convolution_fusion_block(x, filters=128, l2_reg=l2_reg)\n",
    "    x = spectral_spatial_fusion_block(x, filters=128, l2_reg=l2_reg)\n",
    "    \n",
    "    # Change upsampling scale from 4x to 2x\n",
    "    x = upsample_block(x, filters=64, scale=2, use_residual=True, use_depthwise=use_depthwise, use_transpose=use_transpose)\n",
    "    \n",
    "    x_out = Conv2D(input_shape[-1], (3, 3), padding='same', kernel_regularizer=l2(l2_reg))(x)\n",
    "    x_out = Activation('linear')(x_out)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=x_out, name=\"Residual_CNN_SR_Model_2x\")\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# Build and Compile the Model\n",
    "# -----------------------------\n",
    "input_shape = (72, 72, 8)  \n",
    "residual_cnn_inception_sr_model = build_residual_cnn_sr_model(input_shape, use_depthwise=True, use_transpose=True)\n",
    "\n",
    "# Compile with Combined Loss\n",
    "residual_cnn_inception_sr_model.compile(optimizer='adam', loss=lambda y_true, y_pred: combined_loss(y_true, y_pred, residual_cnn_inception_sr_model))\n",
    "\n",
    "# Print total parameters\n",
    "total_params = residual_cnn_inception_sr_model.count_params()\n",
    "print(f\"Total Trainable Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c412dc",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Train the model and get the training history with early stopping\n",
    "history = residual_cnn_inception_sr_model.fit(\n",
    "    X_train_lr, \n",
    "    X_train_hr, \n",
    "    epochs=1000, \n",
    "    batch_size=4, \n",
    "    validation_data=(X_validation_lr, X_validation_hr),\n",
    "    callbacks=[early_stopping]  # Add the early stopping callback here\n",
    ")\n",
    "\n",
    "# Visualize training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size if needed\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1d53ae",
   "metadata": {},
   "source": [
    "## Report all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fcc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def psnr(y_true, y_pred, max_pixel=None):\n",
    "    \"\"\"\n",
    "    Compute PSNR for each spectral band separately and return the average.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Ground truth image, shape (H, W, B)\n",
    "        y_pred: Super-resolved image, shape (H, W, B)\n",
    "        max_pixel: Maximum pixel value (None = use actual max from y_true)\n",
    "    \n",
    "    Returns:\n",
    "        Average PSNR across all bands\n",
    "    \"\"\"\n",
    "    if max_pixel is None:\n",
    "        max_pixel = np.max(y_true)  # Auto-detect max value if not provided\n",
    "\n",
    "    B = y_true.shape[-1]  # Number of spectral bands\n",
    "    psnr_values = []\n",
    "    \n",
    "    for i in range(B):  # Loop over bands\n",
    "        mse = np.mean((y_true[..., i] - y_pred[..., i]) ** 2)\n",
    "        if mse == 0:\n",
    "            psnr_values.append(float('inf'))  # Perfect reconstruction\n",
    "        else:\n",
    "            psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "            psnr_values.append(psnr)\n",
    "    \n",
    "    return np.mean(psnr_values)  # Average across bands\n",
    "\n",
    "# Function to calculate SSIM with channel_axis\n",
    "def ssim_value(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(f\"Shape mismatch: y_true shape {y_true.shape} vs y_pred shape {y_pred.shape}\")\n",
    "    \n",
    "    data_range = y_true.max() - y_true.min()  # Calculate data range from y_true\n",
    "    ssim_val = ssim(y_true, y_pred, data_range=data_range, channel_axis=-1)\n",
    "    return ssim_val\n",
    "\n",
    "# Function to calculate Correlation Coefficient\n",
    "def correlation_coefficient(y_true, y_pred):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    corr_matrix = np.corrcoef(y_true_flat, y_pred_flat)\n",
    "    corr_value = corr_matrix[0, 1]\n",
    "    return corr_value\n",
    "\n",
    "# Function to calculate Spectral Angle Mapper (SAM) in degrees\n",
    "def sam(y_true, y_pred):\n",
    "    y_true_reshaped = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred_reshaped = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "    \n",
    "    non_zero_mask = (np.linalg.norm(y_true_reshaped, axis=1) > 1e-10) & (np.linalg.norm(y_pred_reshaped, axis=1) > 1e-10)\n",
    "    dot_product = np.sum(y_true_reshaped[non_zero_mask] * y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    norm_true = np.linalg.norm(y_true_reshaped[non_zero_mask], axis=1)\n",
    "    norm_pred = np.linalg.norm(y_pred_reshaped[non_zero_mask], axis=1)\n",
    "    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        angles = np.arccos(np.clip(dot_product / (norm_true * norm_pred), -1.0, 1.0))\n",
    "    \n",
    "    if angles.size > 0:\n",
    "        sam_value_degrees = np.mean(angles) * (180 / np.pi)\n",
    "    else:\n",
    "        sam_value_degrees = 0\n",
    "    \n",
    "    return sam_value_degrees\n",
    "\n",
    "# Function to normalize the images\n",
    "def normalize(image):\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    return (image - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n",
    "\n",
    "# Function to calculate Root Mean Squared Error (RMSE) for hyperspectral images (normalized)\n",
    "def rmse_bandwise(y_true, y_pred):\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Shape mismatch between true and predicted images.\")\n",
    "    \n",
    "    bands = y_true.shape[-1]\n",
    "    rmse_per_band = []\n",
    "\n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        \n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)\n",
    "        rmse_band_value = np.sqrt(mse_band)\n",
    "        rmse_per_band.append(rmse_band_value)\n",
    "\n",
    "    # Normalize RMSE by the maximum value in y_true across all bands\n",
    "    max_value = np.max(y_true)\n",
    "    normalized_rmse = np.mean(rmse_per_band) / max_value\n",
    "    return normalized_rmse\n",
    "\n",
    "# Function to calculate ERGAS\n",
    "def ergas(y_true, y_pred, scale):\n",
    "    bands = y_true.shape[-1]\n",
    "    ergas_value = 0\n",
    "    \n",
    "    for b in range(bands):\n",
    "        band_true = y_true[:, :, b]\n",
    "        band_pred = y_pred[:, :, b]\n",
    "        mean_band_true = np.mean(band_true)\n",
    "        \n",
    "        # Calculate RMSE for the band without using a separate function\n",
    "        mse_band = np.mean((band_true - band_pred) ** 2)  # Mean Squared Error for the band\n",
    "        rmse_band = np.sqrt(mse_band)  # Root Mean Squared Error for the band\n",
    "        \n",
    "        ergas_value += (rmse_band / mean_band_true) ** 2\n",
    "    \n",
    "    ergas_value = 100 * (1 / scale) * np.sqrt(ergas_value / bands)\n",
    "    return ergas_value\n",
    "\n",
    "# Assuming hybrid_sr_model is trained, and X_test_lr, X_test_hr are defined\n",
    "predicted_hr_images = residual_cnn_inception_sr_model.predict(X_test_lr, batch_size=4)\n",
    "\n",
    "downscale_factor = 4 # ERGAS downscale factor\n",
    "\n",
    "# Validate shapes match for test and predictions\n",
    "if predicted_hr_images.shape != X_test_hr.shape:\n",
    "    raise ValueError(f\"Shape mismatch: predicted_hr_images shape {predicted_hr_images.shape} vs X_test_hr shape {X_test_hr.shape}\")\n",
    "\n",
    "# Calculate metrics per test sample\n",
    "psnr_values, ssim_values, cc_values, sam_values, ergas_values, rmse_values = [], [], [], [], [], []\n",
    "\n",
    "for i in range(len(X_test_hr)):\n",
    "    psnr_values.append(psnr(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ssim_values.append(ssim_value(X_test_hr[i], predicted_hr_images[i]))\n",
    "    cc_values.append(correlation_coefficient(X_test_hr[i], predicted_hr_images[i]))\n",
    "    sam_values.append(sam(X_test_hr[i], predicted_hr_images[i]))\n",
    "    ergas_values.append(ergas(X_test_hr[i], predicted_hr_images[i], downscale_factor))\n",
    "    rmse_values.append(rmse_bandwise(X_test_hr[i], predicted_hr_images[i]))\n",
    "\n",
    "# Average metrics\n",
    "average_psnr = np.mean(psnr_values)\n",
    "average_ssim = np.mean(ssim_values)\n",
    "average_cc = np.mean(cc_values)\n",
    "average_sam = np.mean(sam_values)\n",
    "average_ergas = np.mean(ergas_values)\n",
    "average_rmse = np.mean(rmse_values)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Average PSNR on the test set:\", average_psnr)\n",
    "print(\"Average SSIM on the test set:\", average_ssim)\n",
    "print(\"Average SAM on the test set (in degrees):\", average_sam)\n",
    "print(\"Average Correlation Coefficient on the test set:\", average_cc)\n",
    "print(\"Average ERGAS on the test set:\", average_ergas)\n",
    "print(\"Average RMSE:\", average_rmse)  # Indicate RMSE is normalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
